- hosts: controlplane1
  become: yes
  vars_files:
    - /opt/mgmt/values-top.yaml
  vars:
    calico_ver: "{{ platform.assets.calico.version }}"
    calico_base: "https://raw.githubusercontent.com/projectcalico/calico/{{ calico_ver }}/manifests"

  tasks:
    - name: Sanity | Show Calico version/URLs
      debug:
        msg:
          - "Calico version: {{ calico_ver }}"
          - "Manifests base: {{ calico_base }}"

    - name: Install operator CRDs (server-side apply; avoids 256KB annotation issue)
      shell: |
        set -eu
        kubectl apply --server-side -f {{ calico_base }}/operator-crds.yaml
      args:
        executable: /bin/bash
      register: crd_apply

    - name: Show result (CRDs)
      debug:
        var: crd_apply.stdout_lines

    - name: Install/upgrade Tigera operator (server-side apply)
      shell: |
        set -eu
        kubectl apply --server-side -f {{ calico_base }}/tigera-operator.yaml
      args:
        executable: /bin/bash
      register: op_apply

    - name: Show result (operator)
      debug:
        var: op_apply.stdout_lines

    - name: Download Calico custom-resources.yaml (edit locally if needed)
      get_url:
        url: "{{ calico_base }}/custom-resources.yaml"
        dest: /root/custom-resources.yaml
        mode: '0644'
        force: yes

    - name: Apply Calico custom resources (server-side apply)
      shell: |
        set -eu
        kubectl apply --server-side -f /root/custom-resources.yaml
      args:
        executable: /bin/bash
      register: cr_apply

    - name: Show result (custom resources)
      debug:
        var: cr_apply.stdout_lines

    - name: Wait for tigera-operator deployment to be ready
      shell: |
        set -eu
        kubectl -n tigera-operator rollout status deploy/tigera-operator --timeout=300s
      args:
        executable: /bin/bash
      register: op_rollout
      retries: 3
      delay: 15
      until: op_rollout.rc == 0
      changed_when: false

    - name: Wait for calico-node DaemonSet to be ready
      shell: |
        set -eu
        kubectl -n calico-system rollout status ds/calico-node --timeout=600s
      args:
        executable: /bin/bash
      register: node_rollout
      retries: 6
      delay: 20
      until: node_rollout.rc == 0
      changed_when: false

    - name: Detect machine architecture
      shell: uname -m
      register: arch_out
      changed_when: false

    - name: Map architecture to Calico binary name
      set_fact:
        calicoctl_arch: >-
          {{ 'amd64' if arch_out.stdout in ['x86_64'] else
             'arm64' if arch_out.stdout in ['aarch64','arm64'] else
             'amd64' }}

    - name: Install kubectl-calico plugin (matches Calico version)
      get_url:
        url: "https://github.com/projectcalico/calico/releases/download/{{ calico_ver }}/calicoctl-linux-{{ calicoctl_arch }}"
        dest: /usr/local/bin/kubectl-calico
        mode: '0755'

    - name: Alias `calicoctl` to `kubectl calico` for root
      lineinfile:
        path: /root/.bashrc
        line: "alias calicoctl='kubectl calico'"
        regexp: "^alias calicoctl='kubectl calico'$"
        state: present
        insertafter: EOF
        create: yes

    - name: Show Calico components
      shell: |
        set -eu
        kubectl get pods -A | egrep 'calico|tigera' || true
      args:
        executable: /bin/bash
      changed_when: false

    # Install the Helm package manager

    - name: Download the Helm package manager
      get_url:
        url: https://get.helm.sh/helm-v{{ platform.assets.helm.version }}-linux-amd64.tar.gz
        dest: /tmp/helm-linux-amd64.tar.gz
        mode: '0700'

    - name: Unpack the Helm distribution
      shell: tar -zxvf /tmp/helm-linux-amd64.tar.gz -C /tmp

    - name: Extract the Helm binary
      shell: mv /tmp/linux-amd64/helm /usr/local/bin/helm

    - name: Install the Stable Helm repository
      shell: |
        helm repo add stable https://charts.helm.sh/stable
        helm repo update

    # Install the base components

    - name: Create the base namespace
      shell: kubectl create namespace top

    - name: Create the Docker Registry pull secret inside all custom namespaces
      shell: "kubectl create -n top secret generic admin-password --from-literal=admin-user=admin --from-literal=admin-password={{ platform.admin.password }}"

